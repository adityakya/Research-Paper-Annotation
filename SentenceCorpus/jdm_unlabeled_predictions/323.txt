AIMX--: taking falsificationist perspective present paper identifies two major shortcomings existing approaches comparative model evaluations general strategy classifications particular
MISC--: number failure consider systematic error number neglect global model fit
MISC--: using adherence measures evaluate competing models implicitly makes unrealistic assumption error associated model predictions entirely random
OWNX--: means simple schematic examples we show failure discriminate between systematic random error seriously undermines this approach model evaluation
MISC--: second approaches treat random versus systematic error appropriately usually rely relative model fit infer model strategy most likely generated data
CONT--: however model comparatively yielding best fit may still invalid
OWNX--: we demonstrate taking granted vital requirement model itself should adequately describe data easily lead flawed conclusions
MISC--: thus prior considering relative discrepancy competing models necessary assess their absolute fit thus again attempt falsification
MISC--: finally scientific value model fit discussed broader perspective
OWNX--: comparative evaluation theories issue fundamental importance all sciences
MISC--: general many disciplines proceed submitting particular theory derived hypothesis empirical tests evaluating through logic verification falsification
MISC--: although tests constructed differentiate between models experimentum crucis given opposing predictions derived citation more common their comparison proceeds more indirectly
MISC--: specifically underlying assumptions predictions derived each particular model tested independently
MISC--: over time instances confirmation disconfirmation accumulated each model
MISC--: according classical falsificationist logic citation model repeatedly fails relevant tests eventually discarded
OWNX--: thereby question better theory model answered indirectly long run model makes testable falsifiable predictions endures critical tests
MISC--: there numerous implementations this approach jdm research well stated arguments been formulated favor testing critical properties central assumptions single models citation
OWNX--: indeed typical variant conduct series investigations successively shed light determinants bounding conditions certain effects theories
MISC--: however discontent testing properties single models isolation been voiced
MISC--: line argument summarized follows citation problematic test specific hypothesis derived single model against indefinite number unspecified alternatives
OWNX--: rather argued we need compare alternative models directly
MISC--: line arguments popular approach specify several competing models directly compare terms their ability account empirical data citation
MISC--: one particular variant specific jdm research strategy classification approach attempts identify decision strategy individual most likely used citation
MISC--: following idea people adaptively select set strategies citation models compared level individual subjects superior model retained description how decision maker proceeded
AIMX--: current paper we focus comparative model testing general more jdm specific procedure strategy classification particular
OWNX--: following notion good test theory one implements sufficiently high hurdle overcome this theory citation we identify two major shortcomings existing approaches comparative model evaluation number failure distinguish between random systematic error number neglect global model fit
