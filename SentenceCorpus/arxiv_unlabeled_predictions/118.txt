MISC--: we consider least square linear regression problem regularization symbol norm problem usually referred lasso
AIMX--: this paper we present detailed asymptotic analysis model consistency lasso
OWNX--: various decays regularization parameter we compute asymptotic equivalents probability correct model selection i e variable selection
OWNX--: specific rate decay we show lasso selects all variables should enter model probability tending one exponentially fast while selects all other variables strictly positive probability
AIMX--: we show this property implies if we run lasso several bootstrapped replications given sample then intersecting supports lasso bootstrap estimates leads consistent model selection
MISC--: this novel variable selection algorithm referred bolasso compared favorably other linear regression methods synthetic data datasets uci machine learning repository
OWNX--: regularization symbol norm attracted lot interest recent years machine learning statistics signal processing
MISC--: context least square linear regression problem usually referred lasso citation
MISC--: much early effort been dedicated algorithms solve optimization problem efficiently
OWNX--: particular lars algorithm singleemcite lars allows find entire regularization path i e set solutions all values regularization parameters at cost single matrix inversion
MISC--: moreover well known justification regularization symbol norm leads sparse solutions i e loading vectors many zeros thus performs model selection
OWNX--: recent works citation looked precisely at model consistency lasso i e if we know data were generated sparse loading vector does lasso actually recover when number observed data points grows
MISC--: case fixed number covariates lasso does recover sparsity pattern if only if certain simple condition generating covariance matrices verified citation
MISC--: particular low correlation settings lasso indeed consistent
MISC--: however presence strong correlations lasso cannot consistent shedding light potential problems procedures variable selection
MISC--: adaptive versions where data dependent weights added symbol norm then allow keep consistency all situations citation
AIMX--: this paper we first derive detailed asymptotic analysis sparsity pattern selection lasso estimation procedure extends previous analysis citation focusing specific decay regularization parameter
MISC--: we show when decay proportional symbol where symbol number observations then lasso will select all variables should enter model relevant variables probability tending one exponentially fast symbol while selects all other variables irrelevant variables strictly positive probability
MISC--: if several datasets generated same distribution were available then latter property would suggest consider intersection supports lasso estimates each dataset all relevant variables would always selected all datasets while irrelevant variables would enter models randomly intersecting supports sufficiently many different datasets would simply eliminate them
MISC--: however practice only one dataset given but resampling methods bootstrap exactly dedicated mimic availability several datasets resampling same unique dataset citation
AIMX--: this paper we show when using bootstrap intersecting supports we actually get consistent model estimate without consistency condition required regular lasso
OWNX--: we refer this new procedure bolasso bo otstrap enhanced l east b s olute s hrinkage o perator
OWNX--: finally our bolasso framework could seen voting scheme applied supports bootstrap lasso estimates however our procedure may rather considered consensus combination scheme we keep largest subset variables all regressors agree terms variable selection our case provably consistent also allows get rid potential additional hyperparameter
AIMX--: paper organized follows mysec analysis we present asymptotic analysis model selection lasso mysec bootstrap we describe bolasso algorithm well its proof model consistency while mysec simulations we illustrate our results synthetic data where true sparse generating model known data uci machine learning repository
OWNX--: sketches proofs found appendix paragraph notations vector symbol we let denote symbol symbol norm symbol symbol norm symbol symbol norm
MISC--: symbol symbol denotes sign symbol defined symbol if symbol symbol if symbol symbol if symbol
MISC--: vector symbol symbol denotes vector signs elements symbol
MISC--: moreover given vector symbol subset symbol symbol symbol denotes vector symbol elements symbol indexed symbol
MISC--: similarly matrix symbol symbol denotes submatrix symbol composed elements symbol whose rows symbol columns symbol
