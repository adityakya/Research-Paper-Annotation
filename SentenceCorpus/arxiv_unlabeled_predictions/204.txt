OWNX--: we present multiplicative updates solving hard soft margin support vector machines svm non negative kernels
MISC--: they follow natural extension updates non negative matrix factorization
MISC--: no additional parameter setting choosing learning rate required
MISC--: experiments demonstrate rapid convergence good classifiers
OWNX--: we analyze rates asymptotic convergence updates establish tight bounds
OWNX--: we test performance several datasets using various non negative kernels report equivalent generalization errors standard svm
MISC--: support vector machines svm now routinely used many classification problems machine learning citation due their ease use ability generalize
MISC--: basic case input data corresponding two groups mapped into higher dimensional space where maximum margin hyperplane computed separate them
OWNX--: kernel trick used ensure mapping into higher dimensional space never explicitly calculated
MISC--: this formulated non negative quadratic programming nqp problem there efficient algorithms solve citation
MISC--: svm trained using variants gradient descent method applied nqp
MISC--: although methods quite efficient citation their drawback requirement setting learning rate
MISC--: subset selection methods alternative approach solving svm nqp problem citation
MISC--: at high level they work splitting arguments quadratic function at each iteration into two sets fixed set where arguments held constant working set variables being optimized current iteration
MISC--: methods citation though efficient space time still require heuristic exchange arguments between working fixed sets
MISC--: alternative algorithm solving general nqp problem been applied svm citation
OWNX--: algorithm called m textsuperscript uses multiplicative updates iteratively converge solution
MISC--: does not require any heuristics setting learning rate choosing how split argument set
OWNX--: this paper we reformulate dual svm problem demonstrate connection non negative matrix factorization nmf algorithm citation
MISC--: nmf employs multiplicative updates very successful practice due its independence learning rate parameter low computational complexity ease implementation
MISC--: new formulation allows us devise multiplicative updates solving svm non negative kernels output value kernel function greater equal zero
MISC--: requirement non negative kernel not very restrictive since their set includes many popular kernels gaussian polynomial even degree etc
MISC--: new updates possess all good properties nmf algorithm independence hyper parameters low computational complexity ease implementation
MISC--: furthermore new algorithm converges faster than previous multiplicative solution svm problem citation both asymptotically proof provided practice
AIMX--: we also show how solve svm problem soft margin using new algorithm
