OWNX--: we present method learning max weight matching predictors bipartite graphs
OWNX--: method consists performing maximum posteriori estimation exponential families sufficient statistics encode permutations data features
OWNX--: although inference general hard we show one very relevant application web page ranking exact inference efficient
MISC--: general model instances appropriate sampler readily available
BASE--: contrary existing max margin matching models our approach statistically consistent addition experiments increasing sample sizes indicate superior improvement over models
OWNX--: we apply method graph matching computer vision well standard benchmark dataset learning web page ranking we obtain state art results particular improving max margin variants
OWNX--: drawback this method respect max margin alternatives its runtime large graphs comparatively high
MISC--: maximum weight bipartite matching problem henceforth matching problem fundamental problem combinatorial optimization citation
MISC--: this problem finding heaviest perfect match weighted bipartite graph
MISC--: exact optimal solution found cubic time standard methods hungarian algorithm
MISC--: this problem practical interest because nicely model real world applications
MISC--: example computer vision crucial problem finding correspondence between sets image features often modeled matching problem citation
MISC--: ranking algorithms based matching framework citation clustering algorithms citation
MISC--: when modeling problem one matching one central question choice weight matrix
OWNX--: problem real applications we typically observe edge feature vectors not edge weights
MISC--: consider concrete example computer vision difficult tell what similarity score between two image feature points but straightforward extract feature vectors e g sift associated those points
OWNX--: this setting natural ask whether we could parameterize features use labeled matches order estimate parameters given graphs similar features their resulting max weight matches also similar
MISC--: this idea parameterizing algorithms then optimizing agreement data called structured estimation citation
MISC--: citation citation describe max margin structured estimation formalisms this problem
MISC--: max margin structured estimators appealing they try minimize loss one really cares about structured losses hamming loss example
CONT--: however structured losses typically piecewise constant parameters eliminates any hope using smooth optimization directly
MISC--: max margin estimators instead minimize surrogate loss easier optimize namely convex upper bound structured loss citation
MISC--: practice results often good but known convex relaxations produce estimators statistically inconsistent citation i e algorithm general fails obtain best attainable model limit infinite training data
MISC--: inconsistency multiclass support vector machines well known issue literature received careful examination recently citation
AIMX--: motivated inconsistency issues max margin structured estimators well well known benefits having full probabilistic model this paper we present maximum posteriori map estimator matching problem
OWNX--: observed data edge feature vectors labeled matches provided training
OWNX--: we then maximize conditional posterior likelihood matches given observed data
OWNX--: we build exponential family model where sufficient statistics mode distribution prediction solution max weight matching problem
MISC--: resulting partition function symbol p complete compute exactly
OWNX--: however we show learning rank applications model instance tractable
OWNX--: we then compare performance our model instance against large number state art ranking methods including dorm citation approach only differs our model instance using max margin instead map formulation
OWNX--: we show very competitive results standard webpage ranking datasets particular we show our model performs better than par dorm
OWNX--: intractable model instances we show problem approximately solved using sampling we provide experiments computer vision domain
MISC--: however fastest suitable sampler still quite slow large models case max margin matching estimators like those citation citation likely preferable even spite their potential inferior accuracy
