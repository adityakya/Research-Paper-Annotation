MISC--: learning problems form important category computational tasks generalizes many computations researchers apply large real life data sets
OWNX--: we ask what concept classes learned privately namely algorithm whose output does not depend too heavily any one input specific training example
AIMX--: more precisely we investigate learning algorithms satisfy differential privacy notion provides strong confidentiality guarantees contexts where aggregate information released about database containing sensitive information about individuals ifnum full we present several basic results demonstrate general feasibility private learning relate several models previously studied separately contexts privacy standard learning
MISC--: our goal broad understanding resources required private learning terms samples computation time interaction
MISC--: we demonstrate ignoring computational constraints possible privately agnostically learn any concept class using sample size approximately logarithmic cardinality concept class
MISC--: therefore almost anything learnable learnable privately specifically if concept class learnable non private algorithm polynomial sample complexity output size then learned privately using polynomial number samples
OWNX--: we also present computationally efficient private pac learner class parity functions
MISC--: this result dispels similarity between learning noise private learning both must robust small changes inputs since parity thought very hard learn given random classification noise
MISC--: local randomized response algorithms practical class private algorithms received extensive investigation
OWNX--: we provide precise characterization local private learning algorithms
MISC--: we show concept class learnable local algorithm if only if learnable statistical query sq model
MISC--: therefore local private learning algorithms similarity learning noise stronger local learning equivalent sq learning sq algorithms include most known noise tolerant learning algorithms
OWNX--: finally we present separation between power interactive noninteractive local learning algorithms
MISC--: because equivalence sq learning this result also separates adaptive nonadaptive sq learning
MISC--: data privacy problem modern databases similar faced statistical agencies medical researchers learn publish global analyses population while maintaining confidentiality participants survey
MISC--: there vast body work this problem statistics computer science
MISC--: however until recently most schemes proposed literature lacked rigorous analysis privacy utility
MISC--: recent line work ifnum full citation initiated dinur nissim citation called private data analysis seeks place data privacy firmer theoretical foundations been successful at formulating strong yet attainable privacy definition
MISC--: notion differential privacy citation emerged this line work provides rigorous guarantees even presence malicious adversary access arbitrary auxiliary information
MISC--: requires whether individual supplies her actual fake information almost no effect outcome analysis
OWNX--: given this definition natural ask what computational tasks performed while maintaining privacy
MISC--: research data privacy extent formalizes precise goals mostly focused function evaluation what value symbol
MISC--: namely how much privacy possible if one wishes release approximation particular function symbol evaluated database symbol notable exception recent work mcsherry talwar using differential privacy design auction mechanisms citation
MISC--: our goal expand utility private protocols examining other computational tasks performed privacy preserving manner paragraph private learning ifnum full learning problems form important category computational tasks generalizes many computations researchers apply large real life data sets
OWNX--: this work we ask what learned privately namely algorithm whose output does not depend too heavily any one input specific training example
MISC--: our goal broad understanding resources required private learning terms samples computation time interaction
AIMX--: we examine two basic notions ifnum full computational learning theory learning valiant s probabilistically approximately correct pac learning citation model kearns statistical query sq model citation
OWNX--: informally concept function examples labels class concepts learnable if any distribution symbol examples one given limited access examples sampled symbol labeled according some target concept symbol find small circuit hypothesis predicts symbol s labels high probability over future examples taken same distribution
CONT--: pac model learning algorithm access polynomial number labeled examples
OWNX--: sq model instead accessing examples directly learner specify some properties i e predicates examples he given estimate up additive polynomially small error probability random example chosen symbol satisfies property
MISC--: pac learning strictly stronger than sq learning citation
OWNX--: we model statistical database vector symbol where each entry been contributed individual
CONT--: when analyzing how well private algorithm learns concept class we assume entries symbol database random examples generated iid underlying distribution symbol labeled target concept symbol
OWNX--: this exactly how not necessarily private learners analyzed
MISC--: instance example might consist individual s gender age blood pressure history label whether this individual had heart attack
MISC--: algorithm learn predict whether individual had heart attack based gender age blood pressure history generated according symbol
OWNX--: we require private algorithm keep entire examples not only labels confidential
MISC--: scenario above translates not revealing each participant s gender age blood pressure history heart attack incidence
MISC--: more precisely output private learner should not significantly affected if particular example symbol replaced arbitrary symbol all symbol symbol
OWNX--: contrast correctness utility analyzed respect distribution symbol differential privacy worst case notion
OWNX--: hence when we analyze privacy our learners we do not make any assumptions underlying distribution
MISC--: assumptions fragile particular would fall apart presence auxiliary knowledge ifnum full also called background knowledge side information adversary might conditioned adversary s auxiliary knowledge distribution over examples might look very different symbol
MISC--: shiva explain this point full version
