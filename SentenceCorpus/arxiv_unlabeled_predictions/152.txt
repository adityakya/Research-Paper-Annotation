MISC--: multi task learning several related tasks considered simultaneously hope appropriate sharing information across tasks each task may benefit others
MISC--: context learning linear functions supervised classification regression this achieved including priori information about weight vectors associated tasks how they expected related each other
AIMX--: this paper we assume tasks clustered into groups unknown beforehand tasks within group similar weight vectors
OWNX--: we design new spectral norm encodes this priori assumption without prior knowledge partition tasks into groups resulting new convex optimization formulation multi task learning
AIMX--: we show simulations synthetic examples textsc iedb mhc i binding dataset our approach outperforms well known convex methods multi task learning well related non convex methods dedicated same problem
OWNX--: regularization emerged dominant theme machine learning statistics providing intuitive principled tool learning high dimensional data
MISC--: particular regularization squared euclidean norms squared hilbert norms been thoroughly studied various settings leading efficient practical algorithms based linear algebra very good theoretical understanding see eg citation
OWNX--: recent years regularization non hilbert norms symbol norms symbol also generated considerable interest inference linear functions supervised classification regression
MISC--: indeed norms sometimes both make problem statistically numerically better behaved impose various priori knowledge problem
OWNX--: example symbol norm sum absolute values imposes some components equal zero widely used estimate sparse functions citation while various combinations symbol norms defined impose various sparsity patterns
AIMX--: while most recent work focused studying properties simple well known norms we take opposite approach this paper
OWNX--: assuming given prior knowledge how we design norm will enforce
MISC--: more precisely we consider problem multi task learning recently emerged very promising research direction various applications citation
MISC--: multi task learning several related inference tasks considered simultaneously hope appropriate sharing information across tasks each one may benefit others
MISC--: when linear functions estimated each task associated weight vector common strategy design multi task learning algorithm translate some prior hypothesis about how tasks related each other into constraints different weight vectors
MISC--: example constraints typically weight vectors different tasks belong euclidean ball centered at origin citation implies no sharing information between tasks apart size different vectors i e amount regularization b ball unknown center citation enforces similarity between different weight vectors c unknown low dimensional subspace citation
AIMX--: this paper we consider different prior hypothesis we believe could more relevant some applications hypothesis different tasks fact clustered into different groups weight vectors tasks within group similar each other
OWNX--: key difference citation where similar hypothesis studied we don t assume groups known priori sense our goal both identify clusters use them multi task learning
MISC--: important situation motivates this hypothesis case where most tasks indeed related each other but few outlier tasks very different case may better impose similarity low dimensional constraints only subset tasks thus forming cluster rather than all tasks
MISC--: another situation interest when one expect natural organization tasks into clusters when one wants model preferences customers believes there few general types customers similar preferences within each type although one does not know beforehand customers belong types
OWNX--: besides improved performance if hypothesis turns out correct we also expect this approach able identify cluster structure among tasks product inference step eg identify outliers groups customers interest further understanding structure problem
OWNX--: order translate this hypothesis into working algorithm we follow general strategy mentioned above design norm penalty over set weights used regularization classical inference algorithms
OWNX--: we construct penalty first assuming partition tasks into clusters known similarly citation
BASE--: we then attempt optimize objective function inference algorithm over set partitions strategy proved useful other contexts multiple kernel learning citation
BASE--: this optimization problem over set partitions being computationally challenging we propose convex relaxation problem results efficient algorithm
