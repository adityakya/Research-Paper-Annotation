MISC--: we consider general class regularization methods learn vector parameters basis linear measurements
MISC--: well known if regularizer nondecreasing function inner product then learned vector linear combination input data
OWNX--: this result known representer theorem at basis kernel based methods machine learning
AIMX--: this paper we prove necessity above condition thereby completing characterization kernel methods based regularization
OWNX--: we further extend our analysis regularization methods learn matrix problem motivated application multi task learning
AIMX--: this context we study more general representer theorem holds larger class regularizers
OWNX--: we provide necessary sufficient condition class matrix regularizers highlight them some concrete examples practical importance
OWNX--: our analysis uses basic principles matrix theory especially useful notion matrix nondecreasing function
MISC--: regularization hilbert spaces important methodology learning examples long history variety fields
MISC--: been studied different perspectives statistics citation optimal estimation citation recently been focus attention machine learning theory see example citation references therein
OWNX--: regularization formulated optimization problem involving error term regularizer
MISC--: regularizer plays important role favors solutions certain desirable properties
MISC--: long been observed certain regularizers exhibit appealing property called representer theorem states there exists solution regularization problem linear combination data citation
OWNX--: this property important computational implications context regularization positive semidefinite kernels because makes high infinite dimensional problems this type into finite dimensional problems size number available data citation
OWNX--: topic interest this paper will determine conditions under representer theorems hold
OWNX--: first half paper we describe property regularizer should satisfy order give rise representer theorem
OWNX--: turns out this property simple geometric interpretation regularizer equivalently expressed nondecreasing function hilbert space norm
OWNX--: thus we show this condition already been known sufficient representer theorems also necessary
OWNX--: second half paper we depart context hilbert spaces focus class problems matrix structure plays important role
MISC--: problems recently appeared several machine learning applications we show modified version representer theorem holds class regularizers significantly larger than former context
OWNX--: we shall see matrix regularizers important context multi task learning matrix columns parameters different regression tasks regularizer encourages certain dependences across tasks
OWNX--: general we consider problems framework tikhonov regularization citation
OWNX--: this regularization approach receives set input output data symbol symbol selects vector symbol solution optimization problem
MISC--: here symbol prescribed hilbert space equipped inner product symbol symbol set possible output values
MISC--: optimization problems encountered regularization type min left bigl left w x rb dots w x m right left y dots y m right bigr omega w w right where symbol regularization parameter
MISC--: function symbol called error function symbol called regularizer
OWNX--: error function measures error data
MISC--: typically decomposes sum univariate functions
MISC--: example regression common choice would sum square errors symbol
MISC--: function symbol called regularizer favors certain regularity properties vector symbol small norm chosen based available prior information about target vector
MISC--: some hilbert spaces sobolev spaces regularizer measure smoothness smaller norm smoother function
MISC--: this framework includes several well studied learning algorithms ridge regression citation support vector machines citation many more see citation references therein
OWNX--: important aspect practical success this approach observation certain choices regularizer solving eqref eq reg intro reduces identifying symbol parameters not symbol
MISC--: specifically when regularizer square hilbert space norm representer theorem holds there exists solution symbol eqref eq reg intro linear combination input vectors w sum i m c i x i where symbol some real coefficients
MISC--: this result simple prove dates at least s see example citation
MISC--: also known extends any regularizer nondecreasing function norm citation
MISC--: several other variants results about representation form eqref eq rt also appeared recent years citation
MISC--: moreover representer theorem been important machine learning particularly within context learning reproducing kernel hilbert spaces citation see citation references therein
OWNX--: our first objective this paper derive necessary sufficient conditions representer theorems hold
MISC--: even though one mainly interested regularization problems more convenient study interpolation problems problems form min left omega w w w x i y i i dots m right
OWNX--: thus we begin this paper section showing how representer theorems interpolation regularization relate
OWNX--: one side representer theorem interpolation easily implies theorem regularization same regularizer any error function
OWNX--: therefore all representer theorems obtained this paper apply equally interpolation regularization
MISC--: other side though converse implication true under certain weak qualifications error function
OWNX--: having addressed this issue we concentrate section proving interpolation problem eqref eq int intro admits solutions representable form eqref eq rt if only if regularizer nondecreasing function hilbert space norm
OWNX--: we provide complete characterization regularizers give rise representer theorems had been open question
OWNX--: furthermore we discuss how our proof motivated geometric understanding representer theorem equivalently expressed monotonicity property regularizer
OWNX--: our second objective formulate study novel question representer theorems matrix problems
OWNX--: make our discussion concrete let us consider problem learning symbol linear regression vectors represented parameters symbol respectively
MISC--: each vector thought task goal jointly learn symbol tasks
MISC--: problems there usually prior knowledge relates tasks often case learning improve if this knowledge appropriately taken into account
MISC--: consequently good regularizer should favor task relations involve all tasks jointly
OWNX--: case interpolation this learning framework formulated concisely symbol where symbol denotes set symbol real matrices column vectors symbol form matrix symbol
MISC--: each task symbol its own input data symbol corresponding output values symbol
MISC--: important feature problems distinguishes them type eqref eq int intro appearance matrix products constraints unlike inner products eqref eq int intro
OWNX--: fact we will discuss section problems type eqref eq matrix intro written form eqref eq int intro
MISC--: consequently representer theorem applies if matrix regularizer nondecreasing function frobenius norm
MISC--: however optimal vector symbol each task represented linear combination only those input vectors corresponding this particular task
OWNX--: moreover regularizers easy see each task eqref eq matrix intro optimized independently
MISC--: hence regularizers no practical interest if tasks expected related
OWNX--: this observation leads us formulate modified representer theorem appropriate matrix problems namely where symbol scalar coefficients symbol
OWNX--: other words we now allow all input vectors present linear combination representing each column optimal matrix
MISC--: result this definition greatly expands class regularizers give rise representer theorems
MISC--: moreover this framework applied many applications where matrix optimization problems involved
CONT--: our immediate motivation however been more specific than namely multi task learning
MISC--: learning multiple tasks jointly been growing area interest machine learning especially during past few years citation
OWNX--: instance some works use regularizers involve trace norm matrix symbol
OWNX--: general idea behind this methodology small trace norm favors low rank matrices
OWNX--: this means tasks columns symbol related they all lie low dimensional subspace symbol
OWNX--: case trace norm representer theorem eqref eq rep matrix intro known hold see citation also discussed section
MISC--: natural therefore ask question similar standard hilbert space single task setting
OWNX--: under conditions regularizer representer theorem holds
OWNX--: section we provide answer proving necessary sufficient condition representer theorems hold expressed simple monotonicity property
MISC--: this property analogous one hilbert space setting but its geometric interpretation now algebraic nature
OWNX--: we also give functional description equivalent this property we show regularizers interest matrix nondecreasing functions quantity symbol
OWNX--: our results cover matrix problems type eqref eq matrix intro already been studied literature
MISC--: but they also point towards some new learning methods may perform well practice now made computationally efficient
OWNX--: thus we close paper discussion possible regularizers satisfy our conditions been used used future machine learning problems
