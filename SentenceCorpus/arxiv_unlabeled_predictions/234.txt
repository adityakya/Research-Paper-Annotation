MISC--: problem multi agent learning adaptation attracted great deal attention recent years
CONT--: been suggested dynamics multi agent learning studied using replicator equations population biology
CONT--: most existing studies so far been limited discrete strategy spaces small number available actions
MISC--: many cases however choices available agents better characterized continuous spectra
AIMX--: this paper suggests generalization replicator framework allows study adaptive dynamics symbol learning agents continuous strategy spaces
MISC--: instead probability vectors agents strategies now characterized probability measures over continuous variables
MISC--: result ordinary differential equations discrete case replaced system coupled integral differential replicator equations describe mutual evolution individual agent strategies
OWNX--: we derive set functional equations describing steady state replicator dynamics examine their solutions several two player games confirm our analytical results using simulations
MISC--: notion autonomous agents learn interacting environment possibly other agents central concept modern distributed ai citation
MISC--: particular interests systems where multiple agents learn concurrently independently interacting each other
MISC--: this multi agent learning problem attracted great deal attention due number important applications
MISC--: among existing approaches multi agent reinforcement learning marl algorithms become increasingly popular due their generality citation
MISC--: although marl does not hold same convergence guarantees single agent case been shown work well practice recent survey see citation
MISC--: analysis standpoint marl represents complex dynamical system where learning trajectories individual agents coupled each other via collective reward mechanism
MISC--: thus desirable know what possible long term behaviors those trajectories
MISC--: specifically one usually interested whether particular game structure those trajectories converge desirable steady state called fixed points oscillate indefinitely between many possibly infinite meta stable states
CONT--: while answering this question proven very difficult most general settings there been some limited progress specific scenarios
MISC--: particular been established simple stateless q learning finite number actions learning dynamics examined using so called replicator equations population biology citation
MISC--: namely if one associates particular biological trait each pure strategy then adaptive learning possibly mixed strategies multi agent settings analogous competitive dynamics mixed population where species evolve according their relative fitness population
OWNX--: this framework been used successfully study various interesting features adaptive dynamics learning agents citation
CONT--: few exceptions e g see citation most existing studies so far focused discrete action spaces limited full analysis learning dynamics games very few actions
MISC--: other hand many practical scenarios strategic interactions between agents better characterized continuous spectra possible choices
MISC--: instance modeling agent s bid auction continuous rather than discrete variable more natural
MISC--: situations agents strategies represented probability density functions defined over continuous set actions
MISC--: course reality all decisions made over discretized subset
CONT--: however rationale using continuous approximation makes dynamics more amenable mathematical analysis
AIMX--: this paper we consider simple symbol learning agents play repeated continuous strategy games
MISC--: agents use boltzmann action selection mechanism controls exploration exploitation tradeoff through single temperature like parameter
MISC--: reward functions agents assumed functions continuous variables instead tensors agent strategies represented probability distribution over those variables
MISC--: contrast finite strategy spaces where learning dynamics captured set coupled ordinary differential equations replicator dynamics continuous strategy games described functional differential equations each agent coupling across different agents equations
MISC--: long term behavior those equations define steady state equilibrium profiles agent strategies
MISC--: shown general steady state strategy profiles replicator dynamics do not correspond nash equilibria game
OWNX--: this discrepancy attributed limited rationality agents due exploration
OWNX--: particular boltzmann action selection mechanism studied here exploration results adding entropic term agents payoff function coefficient governed exploration rate temperature
MISC--: thus when one decreases exploration rate relative importance this term diminishes one able gradually recover correspondence nash equilibria
OWNX--: furthermore games allow uniformly mixed nash equilibrium steady state solution replicator equation identical this uniform nash equilibrium any exploration rate
OWNX--: this because uniform distribution already maximizes entropic term
OWNX--: example game if provided section
OWNX--: rest this paper organized follows next section we provide brief overview relevant literature
OWNX--: section we introduce our model derive replicator equations continuous strategy spaces set coupled non linear functional equations describe steady state strategy profile
OWNX--: section we illustrate framework several examples two agent games provide some detailed results general bi linear quadratic payoffs
OWNX--: finally we conclude paper discussion our results possible future directions section
